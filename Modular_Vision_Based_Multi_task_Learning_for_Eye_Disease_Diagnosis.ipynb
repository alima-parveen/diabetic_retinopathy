{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMQaQqITUmUylwQ5j891aKD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alima-parveen/diabetic_retinopathy/blob/main/Modular_Vision_Based_Multi_task_Learning_for_Eye_Disease_Diagnosis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXInhXO5Wm6c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taHyeLyfXHRO",
        "outputId": "cd6ff90e-4f67-42b5-acd3-784d39ee58b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)"
      ],
      "metadata": {
        "id": "hdOttuXHXP7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "5aYTaeC8XTB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IDRiD Grading Dataset Class for Single Task (baseline)"
      ],
      "metadata": {
        "id": "Fux2zDlfXcPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class for DR grading\n",
        "class IDRiDGradingDataset(Dataset):\n",
        "    def __init__(self, image_dir, grading_csv, transform=None, mode=\"train\"):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.mode = mode\n",
        "        self.grading_df = pd.read_csv(grading_csv)\n",
        "\n",
        "        # Load image names\n",
        "        self.image_names = sorted(os.listdir(image_dir))\n",
        "\n",
        "        # Filter images based on mode (IDRiD-D: 1–413 for train, 414–516 for test)\n",
        "        if mode == \"train\":\n",
        "            self.image_names = [name for name in self.image_names if int(name.split(\"_\")[1].split(\".\")[0]) <= 413]\n",
        "        else:\n",
        "            self.image_names = [name for name in self.image_names if int(name.split(\"_\")[1].split(\".\")[0]) ]\n",
        "\n",
        "        print(f\"Mode: {mode}, Found {len(self.image_names)} images in {image_dir}\")\n",
        "        if len(self.image_names) == 0:\n",
        "            raise ValueError(f\"No images found in {image_dir} for mode {mode}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_names[idx]\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Load grading label\n",
        "        img_id = img_name.split(\".\")[0]\n",
        "        row = self.grading_df[self.grading_df[\"Image name\"] == img_id]\n",
        "        if not row.empty:\n",
        "            grading_label = torch.tensor(row[\"Retinopathy grade\"].values[0], dtype=torch.long)\n",
        "        else:\n",
        "            print(f\"Warning: No grading label for {img_id}, using default 0\")\n",
        "            grading_label = torch.tensor(0, dtype=torch.long)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, grading_label, img_name  # Return img_name for visualization"
      ],
      "metadata": {
        "id": "GDfPERnDXaGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification model\n",
        "class GradingModel(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super(GradingModel, self).__init__()\n",
        "        vgg16 = models.vgg16(pretrained=True)\n",
        "        self.encoder = vgg16.features\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.pool(x).view(x.size(0), -1)\n",
        "        return self.classifier(x)"
      ],
      "metadata": {
        "id": "4L6ELCqXYq_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and evaluation\n",
        "def train_grading_model(model, train_loader, val_loader, num_epochs=10, results_dir=\"results\"):\n",
        "    # Create results directory\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "    log_file = os.path.join(results_dir, \"training_log.txt\")\n",
        "    metrics_file = os.path.join(results_dir, \"metrics.csv\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
        "\n",
        "    if len(val_loader) == 0:\n",
        "        raise ValueError(\"Validation DataLoader is empty. Check dataset configuration.\")\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    early_stop_count = 0\n",
        "    metrics = []\n",
        "\n",
        "    # Initialize metrics CSV\n",
        "    with open(metrics_file, \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"Epoch\", \"Train Loss\", \"Val Loss\", \"Accuracy\"])\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", leave=False)\n",
        "        for images, grades, _ in train_loop:\n",
        "            images, grades = images.to(device), grades.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, grades)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            train_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_preds, val_labels = [], []\n",
        "        val_loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\", leave=False)\n",
        "        with torch.no_grad():\n",
        "            for images, grades, _ in val_loop:\n",
        "                images, grades = images.to(device), grades.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, grades)\n",
        "                val_loss += loss.item()\n",
        "                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
        "                val_labels.extend(grades.cpu().numpy())\n",
        "                val_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        accuracy = accuracy_score(val_labels, val_preds)\n",
        "\n",
        "        # Log to console and file\n",
        "        log_message = (f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, \"\n",
        "                       f\"Val Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "        print(log_message)\n",
        "        with open(log_file, \"a\") as f:\n",
        "            f.write(log_message + \"\\n\")\n",
        "\n",
        "        # Save metrics\n",
        "        metrics.append([epoch + 1, train_loss, val_loss, accuracy])\n",
        "        with open(metrics_file, \"a\", newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([epoch + 1, train_loss, val_loss, accuracy])\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            early_stop_count = 0\n",
        "            torch.save(model.state_dict(), os.path.join(results_dir, \"best_grading_model.pth\"))\n",
        "        else:\n",
        "            early_stop_count += 1\n",
        "            if early_stop_count >= 5:\n",
        "                print(\"Early stopping triggered\")\n",
        "                break\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "    # Final evaluation\n",
        "    final_accuracy = accuracy_score(val_labels, val_preds)\n",
        "    class_names = [\"No DR\", \"Mild\", \"Moderate\", \"Severe\", \"Proliferative\"]\n",
        "    report = classification_report(val_labels, val_preds, target_names=class_names, digits=4)\n",
        "    conf_matrix = confusion_matrix(val_labels, val_labels)\n",
        "\n",
        "    # Save final results\n",
        "    with open(log_file, \"a\") as f:\n",
        "        f.write(f\"\\nFinal Validation Accuracy: {final_accuracy:.4f}\\n\")\n",
        "        f.write(\"\\nClassification Report:\\n\")\n",
        "        f.write(report)\n",
        "\n",
        "    with open(os.path.join(results_dir, \"classification_report.txt\"), \"w\") as f:\n",
        "        f.write(report)\n",
        "\n",
        "    # Save confusion matrix\n",
        "    np.savetxt(os.path.join(results_dir, \"confusion_matrix.csv\"), conf_matrix, delimiter=\",\", fmt=\"%d\")\n",
        "\n",
        "    # Visualize confusion matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.savefig(os.path.join(results_dir, \"confusion_matrix.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    return final_accuracy, val_preds, val_labels"
      ],
      "metadata": {
        "id": "Hh7-Kh4BYsMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize sample results\n",
        "def visualize_samples(model, val_loader, results_dir, num_samples=2):\n",
        "    model.eval()\n",
        "    class_names = [\"No DR\", \"Mild\", \"Moderate\", \"Severe\", \"Proliferative\"]\n",
        "    samples_processed = 0\n",
        "\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, grades, img_names in val_loader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "\n",
        "            for i in range(len(images)):\n",
        "                if samples_processed >= num_samples:\n",
        "                    break\n",
        "                img = images[i].cpu().permute(1, 2, 0).numpy()\n",
        "                img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])  # Denormalize\n",
        "                img = np.clip(img, 0, 1)\n",
        "\n",
        "                plt.figure(figsize=(6, 6))\n",
        "                plt.imshow(img)\n",
        "                plt.title(f\"Image: {img_names[i]}\\nPred: {class_names[preds[i]]}\\nTrue: {class_names[grades[i]]}\")\n",
        "                plt.axis(\"off\")\n",
        "                plt.savefig(os.path.join(results_dir, f\"sample_{samples_processed+1}.png\"))\n",
        "                plt.close()\n",
        "\n",
        "                samples_processed += 1\n",
        "\n",
        "            if samples_processed >= num_samples:\n",
        "                break"
      ],
      "metadata": {
        "id": "MNkvLg7TYzLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset paths\n",
        "grading_train_img_dir = \"/content/drive/MyDrive/IDRiD Dataset/B. Disease Grading/1. Original Images/a. Training Set\"\n",
        "grading_test_img_dir = \"/content/drive/MyDrive/IDRiD Dataset/B. Disease Grading/1. Original Images/b. Testing Set\"\n",
        "grading_train_csv = \"/content/drive/MyDrive/IDRiD Dataset/B. Disease Grading/2. Groundtruths/a. IDRiD_Disease Grading_Training Labels.csv\"\n",
        "grading_test_csv = \"/content/drive/MyDrive/IDRiD Dataset/B. Disease Grading/2. Groundtruths/b. IDRiD_Disease Grading_Testing Labels.csv\"\n",
        "results_dir = \"/content/drive/MyDrive/IDRiD Dataset/Grading\""
      ],
      "metadata": {
        "id": "GAxjl5GhY6W3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "pKvlmBFLZEjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasets\n",
        "train_dataset = IDRiDGradingDataset(\n",
        "    image_dir=grading_train_img_dir,\n",
        "    grading_csv=grading_train_csv,\n",
        "    transform=transform,\n",
        "    mode=\"train\"\n",
        ")\n",
        "val_dataset = IDRiDGradingDataset(\n",
        "    image_dir=grading_test_img_dir,\n",
        "    grading_csv=grading_test_csv,\n",
        "    transform=transform,\n",
        "    mode=\"test\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCc04XBaZJMz",
        "outputId": "08190351-f695-4973-dd85-d1138ad11e68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mode: train, Found 413 images in /content/drive/MyDrive/IDRiD Dataset/B. Disease Grading/1. Original Images/a. Training Set\n",
            "Mode: test, Found 103 images in /content/drive/MyDrive/IDRiD Dataset/B. Disease Grading/1. Original Images/b. Testing Set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "PaQX3nZ9ZHQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Debug dataset sizes\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNLuAwVUZLzG",
        "outputId": "64bebd7d-17c9-4042-b600-9e406436ac07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 413\n",
            "Validation dataset size: 103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model = GradingModel().to(device)\n",
        "final_accuracy, val_preds, val_labels = train_grading_model(model, train_loader, val_loader, num_epochs=10, results_dir=results_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4s6Ax7wJZNWz",
        "outputId": "cd97e10a-e9db-4feb-f4f3-2f1f8a96d8d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:03<00:00, 162MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 1.4239, Val Loss: 1.2309, Accuracy: 0.4660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Train Loss: 1.1867, Val Loss: 1.1510, Accuracy: 0.5243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10, Train Loss: 1.0701, Val Loss: 1.2190, Accuracy: 0.4175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Train Loss: 1.0145, Val Loss: 1.1845, Accuracy: 0.5534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Train Loss: 0.9272, Val Loss: 1.0886, Accuracy: 0.5922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10, Train Loss: 0.8464, Val Loss: 1.0753, Accuracy: 0.6117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10, Train Loss: 0.7999, Val Loss: 1.1163, Accuracy: 0.5728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10, Train Loss: 0.7370, Val Loss: 1.0755, Accuracy: 0.5631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Train Loss: 0.6600, Val Loss: 1.1007, Accuracy: 0.5534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Train Loss: 0.6111, Val Loss: 1.2101, Accuracy: 0.6117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize samples\n",
        "visualize_samples(model, val_loader, results_dir, num_samples=2)\n",
        "\n",
        "print(f\"Final Validation Accuracy: {final_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_hWpIl8ZPLr",
        "outputId": "9082d5c1-493b-47df-fe72-6da490594b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Validation Accuracy: 0.6117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IDRiD Lesion Segmentation Dataset Class for Single Task (Baseline)"
      ],
      "metadata": {
        "id": "AeOToj2vXo5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import VGG16_Weights\n",
        "import cv2\n",
        "import logging\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "zbjx1mp3XvqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(filename='/content/drive/MyDrive/IDRiD Dataset/segmentation_training.log', level=logging.INFO,\n",
        "                    format='%(asctime)s - %(levelname)s - %(message)s')"
      ],
      "metadata": {
        "id": "ZGMM1DHSgQrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class for single-task binary segmentation\n",
        "class IDRiDSegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir, seg_dir, transform=None, mode=\"train\"):\n",
        "        self.image_dir = image_dir\n",
        "        self.seg_dir = seg_dir\n",
        "        self.transform = transform\n",
        "        self.mode = mode\n",
        "        self.lesion_suffixes = {\n",
        "            '1. Microaneurysms': 'MA',\n",
        "            '2. Haemorrhages': 'HE',\n",
        "            '3. Hard Exudates': 'EX',\n",
        "            '4. Soft Exudates': 'SE',\n",
        "            '5. Optic Disc': 'OD'\n",
        "        }\n",
        "\n",
        "        # Load image names\n",
        "        self.image_names = sorted([f for f in os.listdir(image_dir) if f.lower().endswith('.jpg')])\n",
        "\n",
        "        # Filter images based on mode (IDRiD-S: 1–54 for train, 55–81 for test)\n",
        "        if mode == \"train\":\n",
        "            self.image_names = [name for name in self.image_names if int(name.split(\"_\")[1].split(\".\")[0]) <= 54]\n",
        "        else:\n",
        "            self.image_names = [name for name in self.image_names if int(name.split(\"_\")[1].split(\".\")[0]) >= 55]\n",
        "\n",
        "        logging.info(f\"Mode: {mode}, Found {len(self.image_names)} images in {image_dir}\")\n",
        "        print(f\"Mode: {mode}, Found {len(self.image_names)} images in {image_dir}\")\n",
        "        if len(self.image_names) == 0:\n",
        "            raise ValueError(f\"No images found in {image_dir} for mode {mode}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_names[idx]\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "        try:\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "            logging.debug(f\"Loaded image: {img_path}\")\n",
        "        except FileNotFoundError:\n",
        "            logging.error(f\"File not found: {img_path}\")\n",
        "            print(f\"File not found: {img_path}\")\n",
        "            img = Image.new('RGB', (256, 256))\n",
        "            return torch.zeros(3, 256, 256), torch.zeros(256, 256), False, img_name\n",
        "\n",
        "        # Load and combine masks for all lesion types into a single binary mask\n",
        "        img_id = img_name.split(\".\")[0]\n",
        "        seg_mask = torch.zeros(256, 256)\n",
        "        valid_mask = False\n",
        "        for lesion_dir, suffix in self.lesion_suffixes.items():\n",
        "            seg_path = os.path.join(self.seg_dir, lesion_dir, f\"{img_id}_{suffix}.tif\")\n",
        "            if os.path.exists(seg_path):\n",
        "                try:\n",
        "                    mask = cv2.imread(seg_path, cv2.IMREAD_GRAYSCALE)\n",
        "                    if mask is None:\n",
        "                        logging.warning(f\"Failed to load mask at {seg_path}, using zero mask\")\n",
        "                        mask = np.zeros((256, 256), dtype=np.uint8)\n",
        "                    else:\n",
        "                        mask = cv2.resize(mask, (256, 256))\n",
        "                        mask_binary = torch.tensor(mask > 0, dtype=torch.float32)\n",
        "                        seg_mask = torch.logical_or(seg_mask, mask_binary).float()  # Ensure float32\n",
        "                        if mask_binary.sum() > 0:\n",
        "                            logging.debug(f\"Loaded non-empty mask for {lesion_dir} in {img_name}: {mask_binary.sum()} pixels\")\n",
        "                            valid_mask = True\n",
        "                        else:\n",
        "                            logging.debug(f\"Loaded empty mask for {lesion_dir} in {img_name}\")\n",
        "                except Exception as e:\n",
        "                    logging.warning(f\"Error loading mask {seg_path}: {str(e)}\")\n",
        "            else:\n",
        "                logging.debug(f\"Mask not found for {seg_path}\")\n",
        "\n",
        "        if not valid_mask:\n",
        "            logging.warning(f\"No valid masks found for {img_name}\")\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        logging.debug(f\"seg_mask type: {seg_mask.dtype}, shape: {seg_mask.shape}\")\n",
        "        return img, seg_mask, valid_mask, img_name"
      ],
      "metadata": {
        "id": "U618amS3gUvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Segmentation model for single binary mask\n",
        "class SegmentationModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SegmentationModel, self).__init__()\n",
        "        self.backbone = models.vgg16(weights=VGG16_Weights.IMAGENET1K_V1).features\n",
        "        self.in_channels = 512  # VGG16 final feature map has 512 channels\n",
        "\n",
        "        # UNet-like decoder matching MTL structure\n",
        "        self.decoder = nn.ModuleList([\n",
        "            nn.Conv2d(self.in_channels, 512, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.Conv2d(512, 256, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.Conv2d(256, 128, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.Conv2d(128, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.Conv2d(64, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.Conv2d(32, 1, 3, padding=1)  # Single channel for binary segmentation\n",
        "        ])\n",
        "\n",
        "        # Initialize weights\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        for layer in self.decoder:\n",
        "            x = layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "EfiJNd3TgrnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dice score for binary segmentation\n",
        "def dice_score(pred, target, threshold=0.1):\n",
        "    pred = (torch.sigmoid(pred) > threshold).float()\n",
        "    smooth = 1e-5\n",
        "    intersection = (pred * target).sum()\n",
        "    pred_sum = pred.sum()\n",
        "    target_sum = target.sum()\n",
        "    dice = (2. * intersection + smooth) / (pred_sum + target_sum + smooth)\n",
        "    logging.debug(f\"Dice score: {dice:.4f}, Intersection: {intersection:.4f}, Pred sum: {pred_sum:.4f}, Target sum: {target_sum:.4f}\")\n",
        "    return dice.item()"
      ],
      "metadata": {
        "id": "LP16aqX8gmzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and evaluation\n",
        "def train_segmentation_model(model, train_loader, val_loader, num_epochs=20, results_dir=\"/content/drive/MyDrive/IDRiD Dataset/Segmentation\"):\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "    log_file = os.path.join(results_dir, \"segmentation_training.log\")\n",
        "    model_file = os.path.join(results_dir, \"best_segmentation_model.pth\")\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(10.0).to(device))\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "    scheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-4, max_lr=2e-3, step_size_up=len(train_loader)*3, mode='triangular2')\n",
        "\n",
        "    if len(val_loader) == 0:\n",
        "        raise ValueError(\"Validation DataLoader is empty. Check dataset configuration.\")\n",
        "\n",
        "    best_dice = 0.0\n",
        "    patience_counter = 0\n",
        "    patience = 5\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        valid_mask_batches = 0\n",
        "        train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", leave=True)\n",
        "        for images, masks, valid_masks, _ in train_loop:\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            valid_masks = valid_masks.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "\n",
        "            seg_loss = 0\n",
        "            if valid_masks.any():\n",
        "                valid_indices = valid_masks.nonzero(as_tuple=True)[0]\n",
        "                if len(valid_indices) > 0:\n",
        "                    logging.debug(f\"Outputs type: {outputs.dtype}, Masks type: {masks.dtype}\")\n",
        "                    seg_loss = criterion(outputs.squeeze(1)[valid_indices], masks[valid_indices].float())\n",
        "                    valid_mask_batches += 1\n",
        "\n",
        "            seg_loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            train_loss += seg_loss.item() if seg_loss != 0 else 0\n",
        "            train_loop.set_postfix({'Seg Loss': f'{seg_loss.item():.4f}' if seg_loss != 0 else '0.0', 'Valid Masks': valid_mask_batches})\n",
        "\n",
        "        avg_train_loss = train_loss / valid_mask_batches if valid_mask_batches > 0 else 0.0\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_dice_scores = []\n",
        "        valid_mask_batches = 0\n",
        "        val_loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\", leave=False)\n",
        "        with torch.no_grad():\n",
        "            for images, masks, valid_masks, _ in val_loop:\n",
        "                images, masks = images.to(device), masks.to(device)\n",
        "                valid_masks = valid_masks.to(device)\n",
        "                outputs = model(images)\n",
        "\n",
        "                seg_loss = 0\n",
        "                if valid_masks.any():\n",
        "                    valid_indices = valid_masks.nonzero(as_tuple=True)[0]\n",
        "                    if len(valid_indices) > 0:\n",
        "                        logging.debug(f\"Validation Outputs type: {outputs.dtype}, Masks type: {masks.dtype}\")\n",
        "                        seg_loss = criterion(outputs.squeeze(1)[valid_indices], masks[valid_indices].float())\n",
        "                        val_dice = dice_score(outputs.squeeze(1)[valid_indices], masks[valid_indices].float())\n",
        "                        val_dice_scores.append(val_dice)\n",
        "                        valid_mask_batches += 1\n",
        "\n",
        "                val_loss += seg_loss.item() if seg_loss != 0 else 0\n",
        "                val_loop.set_postfix({'Seg Loss': f'{seg_loss.item():.4f}' if seg_loss != 0 else '0.0', 'Valid Masks': valid_mask_batches})\n",
        "\n",
        "        avg_val_loss = val_loss / valid_mask_batches if valid_mask_batches > 0 else 0.0\n",
        "        avg_dice = np.mean(val_dice_scores) if val_dice_scores else 0.0\n",
        "\n",
        "        log_message = f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Dice: {avg_dice:.4f}\"\n",
        "        logging.info(log_message)\n",
        "        print(log_message)\n",
        "\n",
        "        # Early stopping based on Dice score\n",
        "        if avg_dice > best_dice:\n",
        "            best_dice = avg_dice\n",
        "            torch.save(model.state_dict(), model_file)\n",
        "            logging.info(\"Saved best model based on Dice score\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                logging.info(f\"Early stopping triggered after {patience} epochs without improvement\")\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    return best_dice"
      ],
      "metadata": {
        "id": "Kc8A8nK5gjKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization\n",
        "def visualize_segmentation_results(model, val_loader, results_dir, num_samples=5):\n",
        "    model.eval()\n",
        "    samples_processed = 0\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks, valid_masks, img_names in val_loader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            seg_preds = torch.sigmoid(outputs.squeeze(1)) > 0.1\n",
        "\n",
        "            for i in range(min(num_samples - samples_processed, images.size(0))):\n",
        "                if not valid_masks[i]:\n",
        "                    continue\n",
        "                img = images[i].cpu().permute(1, 2, 0).numpy()\n",
        "                img = (img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])).clip(0, 1)\n",
        "                pred_mask = seg_preds[i].cpu().numpy()\n",
        "                true_mask = masks[i].cpu().numpy()\n",
        "\n",
        "                plt.figure(figsize=(15, 5))\n",
        "                plt.subplot(1, 3, 1)\n",
        "                plt.title(f\"Image: {img_names[i]}\")\n",
        "                plt.imshow(img)\n",
        "                plt.axis(\"off\")\n",
        "                plt.subplot(1, 3, 2)\n",
        "                plt.title(\"Predicted Mask\")\n",
        "                plt.imshow(pred_mask, cmap=\"gray\")\n",
        "                plt.axis(\"off\")\n",
        "                plt.subplot(1, 3, 3)\n",
        "                plt.title(\"Ground Truth Mask\")\n",
        "                plt.imshow(true_mask, cmap=\"gray\")\n",
        "                plt.axis(\"off\")\n",
        "                plt.savefig(os.path.join(results_dir, f\"segmentation_result_{img_names[i]}.png\"))\n",
        "                plt.close()\n",
        "                logging.info(f\"Generated visualization for {img_names[i]}\")\n",
        "                samples_processed += 1\n",
        "\n",
        "            if samples_processed >= num_samples:\n",
        "                break"
      ],
      "metadata": {
        "id": "boyKRG43g0VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seg_train_img_dir = \"/content/drive/MyDrive/IDRiD Dataset/A. Segmentation/1. Original Images/a. Training Set\"\n",
        "seg_test_img_dir = \"/content/drive/MyDrive/IDRiD Dataset/A. Segmentation/1. Original Images/b. Testing Set\"\n",
        "seg_train_mask_dir = \"/content/drive/MyDrive/IDRiD Dataset/A. Segmentation/2. All Segmentation Groundtruths/a. Training Set\"\n",
        "seg_test_mask_dir = \"/content/drive/MyDrive/IDRiD Dataset/A. Segmentation/2. All Segmentation Groundtruths/b. Testing Set\"\n",
        "results_dir = \"/content/drive/MyDrive/IDRiD Dataset/Segmentation\""
      ],
      "metadata": {
        "id": "3jaDPPFyg7CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "ga0PvVb3hYZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = IDRiDSegmentationDataset(\n",
        "    image_dir=seg_train_img_dir,\n",
        "    seg_dir=seg_train_mask_dir,\n",
        "    transform=transform,\n",
        "    mode=\"train\"\n",
        ")\n",
        "val_dataset = IDRiDSegmentationDataset(\n",
        "    image_dir=seg_test_img_dir,\n",
        "    seg_dir=seg_test_mask_dir,\n",
        "    transform=val_transform,\n",
        "    mode=\"test\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN4QjmSdhO8v",
        "outputId": "98385cae-9053-47bd-c1d2-dd8191d4936b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mode: train, Found 54 images in /content/drive/MyDrive/IDRiD Dataset/A. Segmentation/1. Original Images/a. Training Set\n",
            "Mode: test, Found 27 images in /content/drive/MyDrive/IDRiD Dataset/A. Segmentation/1. Original Images/b. Testing Set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "GmZmED-JhRQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.info(f\"Train dataset size: {len(train_dataset)}\")\n",
        "logging.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-al0o1FhUQa",
        "outputId": "57f5d0a2-b319-40f5-e644-68ad2b61a943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 54\n",
            "Validation dataset size: 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SegmentationModel().to(device)\n",
        "final_dice = train_segmentation_model(model, train_loader, val_loader, num_epochs=10, results_dir=results_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuhKZxDVhiWZ",
        "outputId": "a4d8d2db-0b95-45f8-c7a5-c1442fb5cdda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [Train]: 100%|██████████| 14/14 [02:45<00:00, 11.81s/it, Seg Loss=0.8190, Valid Masks=14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 1.4809, Val Loss: 0.9227, Dice: 0.0821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10 [Train]: 100%|██████████| 14/14 [00:15<00:00,  1.07s/it, Seg Loss=1.0386, Valid Masks=14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Train Loss: 0.9321, Val Loss: 0.8727, Dice: 0.0821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10 [Train]: 100%|██████████| 14/14 [00:13<00:00,  1.04it/s, Seg Loss=0.9088, Valid Masks=14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10, Train Loss: 0.8755, Val Loss: 0.9138, Dice: 0.0821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10 [Train]: 100%|██████████| 14/14 [00:13<00:00,  1.02it/s, Seg Loss=0.6587, Valid Masks=14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Train Loss: 0.8412, Val Loss: 0.8581, Dice: 0.0821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10 [Train]: 100%|██████████| 14/14 [00:13<00:00,  1.04it/s, Seg Loss=0.6942, Valid Masks=14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Train Loss: 0.8099, Val Loss: 0.8048, Dice: 0.0879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10 [Train]: 100%|██████████| 14/14 [00:15<00:00,  1.09s/it, Seg Loss=1.9781, Valid Masks=14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10, Train Loss: 0.7969, Val Loss: 0.7273, Dice: 0.1009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10 [Train]: 100%|██████████| 14/14 [00:15<00:00,  1.10s/it, Seg Loss=0.8089, Valid Masks=14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10, Train Loss: 0.7936, Val Loss: 0.8028, Dice: 0.0879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10 [Train]: 100%|██████████| 14/14 [00:13<00:00,  1.05it/s, Seg Loss=0.6603, Valid Masks=14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10, Train Loss: 0.7519, Val Loss: 0.8235, Dice: 0.1269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10 [Train]: 100%|██████████| 14/14 [00:15<00:00,  1.08s/it, Seg Loss=1.3287, Valid Masks=14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Train Loss: 0.7382, Val Loss: 0.7558, Dice: 0.1024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10 [Train]: 100%|██████████| 14/14 [00:13<00:00,  1.04it/s, Seg Loss=0.6378, Valid Masks=14]\n",
            "                                                                                                "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Train Loss: 0.7089, Val Loss: 0.7206, Dice: 0.1107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_segmentation_results(model, val_loader, results_dir)\n",
        "\n",
        "logging.info(f\"Final Dice Score: {final_dice:.4f}\")\n",
        "print(f\"Final Dice Score: {final_dice:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V2QvNqghkdB",
        "outputId": "9eff4a6d-72c2-46f8-a17e-472983d4a489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Dice Score: 0.1269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IDRiD Multitask Working"
      ],
      "metadata": {
        "id": "TP_NrC8NYdMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "from pathlib import Path\n",
        "from torch.optim.lr_scheduler import CyclicLR"
      ],
      "metadata": {
        "id": "yF_R1ySxZcBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(filename='/content/drive/MyDrive/IDRiD Dataset/training_2.log', level=logging.INFO,\n",
        "                    format='%(asctime)s - %(levelname)s - %(message)s')"
      ],
      "metadata": {
        "id": "5nWmZjT6b94x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset for IDRiD\n",
        "class IDRiDDataset(Dataset):\n",
        "    def __init__(self, image_dir_seg, image_dir_grad, grading_csv=None, seg_dir=None, mode='both', transform=None):\n",
        "        self.image_dir_seg = image_dir_seg\n",
        "        self.image_dir_grad = image_dir_grad\n",
        "        self.grading_csv = pd.read_csv(grading_csv) if grading_csv else None\n",
        "        self.seg_dir = seg_dir\n",
        "        self.mode = mode\n",
        "        self.transform = transform\n",
        "\n",
        "        # Lesion-specific suffixes\n",
        "        self.lesion_suffixes = {\n",
        "            '1. Microaneurysms': 'MA',\n",
        "            '2. Haemorrhages': 'HE',\n",
        "            '3. Hard Exudates': 'EX',\n",
        "            '4. Soft Exudates': 'SE',\n",
        "            '5. Optic Disc': 'OD'\n",
        "        }\n",
        "\n",
        "        # Load image names\n",
        "        self.images = []\n",
        "        self.is_segmentation = {}\n",
        "        self.mask_files = {}\n",
        "        if mode in ['segmentation', 'both'] and seg_dir:\n",
        "            seg_images = [f for f in os.listdir(image_dir_seg) if f.lower().endswith('.jpg')]\n",
        "            self.images.extend(seg_images)\n",
        "            for img in seg_images:\n",
        "                self.is_segmentation[img] = True\n",
        "                self.mask_files[img] = {}\n",
        "            logging.info(f\"Loaded {len(seg_images)} segmentation images from {image_dir_seg}\")\n",
        "        if mode in ['grading', 'both'] and self.grading_csv is not None:\n",
        "            grad_images = [f\"{name}.jpg\" for name in self.grading_csv['Image name']]\n",
        "            for img in grad_images:\n",
        "                self.is_segmentation[img] = img in os.listdir(image_dir_seg)\n",
        "            self.images.extend(grad_images)\n",
        "            logging.info(f\"Loaded {len(grad_images)} grading images from CSV\")\n",
        "        self.images = list(set(self.images))\n",
        "        logging.info(f\"Total unique images: {len(self.images)}\")\n",
        "\n",
        "        # Filter images and detect mask filenames\n",
        "        valid_images = []\n",
        "        mask_counts = {lesion: 0 for lesion in self.lesion_suffixes}\n",
        "        mask_exists = {lesion: 0 for lesion in self.lesion_suffixes}\n",
        "        for img in self.images:\n",
        "            img_path = os.path.join(image_dir_seg, img) if img in os.listdir(image_dir_seg) else os.path.join(image_dir_grad, img)\n",
        "            if not os.path.exists(img_path):\n",
        "                logging.warning(f\"Image not found: {img_path}\")\n",
        "                continue\n",
        "            valid_images.append(img)\n",
        "            if self.is_segmentation.get(img, False) and mode in ['segmentation', 'both'] and seg_dir:\n",
        "                img_base = img.split('.')[0]\n",
        "                num_part = img_base.split('_')[1]\n",
        "                for lesion, suffix in self.lesion_suffixes.items():\n",
        "                    patterns = [\n",
        "                        f\"{img_base}_{suffix}.tif\",\n",
        "                        f\"{img_base}_{suffix}.TIF\",\n",
        "                        f\"{img_base}.tif\",\n",
        "                        f\"IDRiD_{num_part:0>3}_{suffix}.tif\",\n",
        "                        f\"IDRiD_{num_part:0>3}.tif\"\n",
        "                    ]\n",
        "                    mask_path = None\n",
        "                    for pattern in patterns:\n",
        "                        path = os.path.join(seg_dir, lesion, pattern)\n",
        "                        if os.path.exists(path):\n",
        "                            mask_path = path\n",
        "                            self.mask_files[img][lesion] = pattern\n",
        "                            mask_exists[lesion] += 1\n",
        "                            try:\n",
        "                                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "                                if mask is not None and np.sum(mask > 0) > 0:\n",
        "                                    mask_counts[lesion] += 1\n",
        "                            except Exception as e:\n",
        "                                logging.warning(f\"Failed to load mask {mask_path}: {str(e)}\")\n",
        "                            break\n",
        "                    if not mask_path:\n",
        "                        logging.debug(f\"No mask found for {img} in {lesion}\")\n",
        "        self.images = valid_images\n",
        "        logging.info(f\"Valid images after filtering: {len(self.images)}\")\n",
        "        logging.info(f\"Mask files exist: {mask_exists}\")\n",
        "        logging.info(f\"Non-empty mask counts: {mask_counts}\")\n",
        "        print(f\"Mask files exist: {mask_exists}\")\n",
        "        print(f\"Non-empty mask counts: {mask_counts}\")\n",
        "\n",
        "        # Upsample segmentation images only\n",
        "        if mode == 'both':\n",
        "            seg_images = [img for img in self.images if self.is_segmentation.get(img, False)]\n",
        "            if len(seg_images) < 54:\n",
        "                seg_images = seg_images * (54 // len(seg_images) + 1)\n",
        "                seg_images = seg_images[:54]\n",
        "                self.images = seg_images + [img for img in self.images if not self.is_segmentation.get(img, False)]\n",
        "                logging.info(f\"Upsampled segmentation images to {len(seg_images)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.images[idx]\n",
        "        img_path = os.path.join(self.image_dir_seg, img_name)\n",
        "        if not os.path.exists(img_path):\n",
        "            img_path = os.path.join(self.image_dir_grad, img_name)\n",
        "\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            logging.debug(f\"Loaded image: {img_path}\")\n",
        "        except FileNotFoundError:\n",
        "            logging.error(f\"File not found: {img_path}\")\n",
        "            print(f\"File not found: {img_path}\")\n",
        "            image = Image.new('RGB', (512, 512))\n",
        "            return (torch.zeros(3, 512, 512), torch.tensor(-1, dtype=torch.long),\n",
        "                    torch.zeros(512, 512), False, img_name)\n",
        "\n",
        "        grading_label = torch.tensor(-1, dtype=torch.long)\n",
        "        seg_mask = torch.zeros(512, 512)\n",
        "        valid_mask = False\n",
        "\n",
        "        if self.mode in ['grading', 'both'] and self.grading_csv is not None:\n",
        "            img_base = img_name.split('.')[0]\n",
        "            if img_base in self.grading_csv['Image name'].values:\n",
        "                label_row = self.grading_csv[self.grading_csv['Image name'] == img_base]\n",
        "                grading_label = torch.tensor(int(label_row['Retinopathy grade'].values[0]), dtype=torch.long)\n",
        "                logging.debug(f\"Loaded grading label for {img_name}: {grading_label}\")\n",
        "\n",
        "        if self.mode in ['segmentation', 'both'] and self.seg_dir and self.is_segmentation.get(img_name, False):\n",
        "            mask_found = False\n",
        "            for lesion in self.lesion_suffixes:\n",
        "                mask_filename = self.mask_files.get(img_name, {}).get(lesion)\n",
        "                if not mask_filename:\n",
        "                    logging.debug(f\"No mask filename for {img_name} in {lesion}\")\n",
        "                    continue\n",
        "                mask_path = os.path.join(self.seg_dir, lesion, mask_filename)\n",
        "                if os.path.exists(mask_path):\n",
        "                    mask_found = True\n",
        "                    try:\n",
        "                        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "                        if mask is None:\n",
        "                            logging.error(f\"Failed to read mask {mask_path}\")\n",
        "                            continue\n",
        "                        mask = cv2.resize(mask, (512, 512))\n",
        "                        mask_binary = torch.tensor(mask > 0, dtype=torch.float32)\n",
        "                        seg_mask = torch.logical_or(seg_mask, mask_binary)\n",
        "                        if mask_binary.sum() > 0:\n",
        "                            logging.debug(f\"Loaded non-empty mask for {lesion} in {img_name}: {mask_binary.sum()} pixels\")\n",
        "                        else:\n",
        "                            logging.debug(f\"Loaded empty mask for {lesion} in {img_name}\")\n",
        "                    except Exception as e:\n",
        "                        logging.error(f\"Error loading mask {mask_path}: {str(e)}\")\n",
        "                else:\n",
        "                    logging.debug(f\"Mask not found: {mask_path}\")\n",
        "            valid_mask = mask_found\n",
        "            if not mask_found:\n",
        "                logging.warning(f\"No mask files found for {img_name} (segmentation image)\")\n",
        "            elif seg_mask.sum() == 0:\n",
        "                logging.debug(f\"All masks empty for {img_name} (segmentation image)\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, grading_label, seg_mask, valid_mask, img_name"
      ],
      "metadata": {
        "id": "gJzmoyshcB9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced data augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((512, 512)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((512, 512)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "dJo2bNX6cMdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "base_path = '/content/drive/MyDrive/IDRiD Dataset'\n",
        "try:\n",
        "    train_dataset = IDRiDDataset(\n",
        "        image_dir_seg=f'{base_path}/A. Segmentation/1. Original Images/a. Training Set',\n",
        "        image_dir_grad=f'{base_path}/B. Disease Grading/1. Original Images/a. Training Set',\n",
        "        grading_csv=f'{base_path}/B. Disease Grading/2. Groundtruths/a. IDRiD_Disease Grading_Training Labels.csv',\n",
        "        seg_dir=f'{base_path}/A. Segmentation/2. All Segmentation Groundtruths/a. Training Set',\n",
        "        mode='both',\n",
        "        transform=train_transform\n",
        "    )\n",
        "    test_dataset = IDRiDDataset(\n",
        "        image_dir_seg=f'{base_path}/A. Segmentation/1. Original Images/b. Testing Set',\n",
        "        image_dir_grad=f'{base_path}/B. Disease Grading/1. Original Images/b. Testing Set',\n",
        "        grading_csv=f'{base_path}/B. Disease Grading/2. Groundtruths/b. IDRiD_Disease Grading_Testing Labels.csv',\n",
        "        seg_dir=f'{base_path}/A. Segmentation/2. All Segmentation Groundtruths/b. Testing Set',\n",
        "        mode='both',\n",
        "        transform=val_transform\n",
        "    )\n",
        "    logging.info(\"Datasets loaded successfully\")\n",
        "    print(\"Datasets loaded successfully\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error loading datasets: {str(e)}\")\n",
        "    print(f\"Error loading datasets: {str(e)}\")\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vy65a2hcO2L",
        "outputId": "411141fc-2d99-4f8e-eb3e-39f62fa1959a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mask files exist: {'1. Microaneurysms': 54, '2. Haemorrhages': 53, '3. Hard Exudates': 54, '4. Soft Exudates': 26, '5. Optic Disc': 54}\n",
            "Non-empty mask counts: {'1. Microaneurysms': 54, '2. Haemorrhages': 53, '3. Hard Exudates': 54, '4. Soft Exudates': 26, '5. Optic Disc': 54}\n",
            "Mask files exist: {'1. Microaneurysms': 27, '2. Haemorrhages': 27, '3. Hard Exudates': 27, '4. Soft Exudates': 14, '5. Optic Disc': 27}\n",
            "Non-empty mask counts: {'1. Microaneurysms': 27, '2. Haemorrhages': 27, '3. Hard Exudates': 27, '4. Soft Exudates': 14, '5. Optic Disc': 27}\n",
            "Datasets loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
      ],
      "metadata": {
        "id": "yk2chyaTdM3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute class weights for grading\n",
        "grading_csv = pd.read_csv(f'{base_path}/B. Disease Grading/2. Groundtruths/a. IDRiD_Disease Grading_Training Labels.csv')\n",
        "class_counts = grading_csv['Retinopathy grade'].value_counts().sort_index()\n",
        "class_weights = 1.0 / class_counts\n",
        "class_weights = class_weights / class_weights.sum() * len(class_weights)\n",
        "class_weights = torch.tensor(class_weights.values, dtype=torch.float32).to(device)\n",
        "logging.info(f\"Class weights for grading: {class_weights.tolist()}\")"
      ],
      "metadata": {
        "id": "UbxUfPQTdO3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modular MTL Model with Dynamic Routing\n",
        "class MultiTaskModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiTaskModel, self).__init__()\n",
        "        self.backbone = models.mobilenet_v2(weights='IMAGENET1K_V1').features\n",
        "        self.in_channels = 1280\n",
        "\n",
        "        # Classification expert\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(self.in_channels, 5)\n",
        "        )\n",
        "\n",
        "        # Segmentation expert\n",
        "        self.decoder = nn.ModuleList([\n",
        "            nn.Conv2d(self.in_channels, 512, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.Conv2d(512, 256, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.Conv2d(256, 128, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.Conv2d(128, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.Conv2d(64, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.Conv2d(32, 1, 3, padding=1)\n",
        "        ])\n",
        "\n",
        "        # Dynamic routing gate\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(self.in_channels, 2),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "        # Initialize weights\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x, task='both'):\n",
        "        features = self.backbone(x)\n",
        "        gate_weights = self.gate(features)  # [batch_size, 2]\n",
        "\n",
        "        outputs = {}\n",
        "        if task in ['grading', 'both']:\n",
        "            class_out = self.classifier(features)\n",
        "            outputs['grading'] = gate_weights[:, 0].unsqueeze(1) * class_out\n",
        "\n",
        "        if task in ['segmentation', 'both']:\n",
        "            seg_out = features\n",
        "            for layer in self.decoder:\n",
        "                seg_out = layer(seg_out)\n",
        "            outputs['segmentation'] = gate_weights[:, 1].unsqueeze(1).unsqueeze(2).unsqueeze(3) * seg_out\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "oeOW6H3AcThU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Focal loss for segmentation\n",
        "def focal_loss(pred, target, alpha=0.75, gamma=1.0):\n",
        "    bce = nn.BCEWithLogitsLoss(reduction='none')(pred, target)\n",
        "    pt = torch.exp(-bce)\n",
        "    focal = alpha * (1 - pt) ** gamma * bce\n",
        "    return focal.mean()"
      ],
      "metadata": {
        "id": "eBpuMRBhdIdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dice score for binary segmentation\n",
        "def dice_score(pred, target, threshold=0.1):\n",
        "    pred = (torch.sigmoid(pred) > threshold).float()\n",
        "    smooth = 1e-5\n",
        "    intersection = (pred * target).sum()\n",
        "    pred_sum = pred.sum()\n",
        "    target_sum = target.sum()\n",
        "    dice = (2. * intersection + smooth) / (pred_sum + target_sum + smooth)\n",
        "    logging.debug(f\"Dice score: {dice:.4f}, Intersection: {intersection:.4f}, Pred sum: {pred_sum:.4f}, Target sum: {target_sum:.4f}\")\n",
        "    return dice.item()"
      ],
      "metadata": {
        "id": "75gf6tHSdJ_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function with early stopping\n",
        "def train_model(model, train_loader, test_loader, epochs=50, patience=5):\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
        "    scheduler = CyclicLR(optimizer, base_lr=1e-4, max_lr=2e-3, step_size_up=len(train_loader)*3, mode='triangular2')\n",
        "    class_criterion = nn.CrossEntropyLoss(weight=class_weights, ignore_index=-1)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    patience_counter = 0\n",
        "    try:\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            train_class_loss, train_seg_loss = 0.0, 0.0\n",
        "            valid_mask_batches = 0\n",
        "            train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=True)\n",
        "            for images, grading_labels, seg_masks, valid_masks, img_names in train_bar:\n",
        "                images, grading_labels, seg_masks = images.to(device), grading_labels.to(device), seg_masks.to(device)\n",
        "                valid_masks = valid_masks.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(images, task='both')\n",
        "\n",
        "                class_loss = class_criterion(outputs['grading'], grading_labels) if 'grading' in outputs else 0\n",
        "                seg_loss = 0\n",
        "                if 'segmentation' in outputs and valid_masks.any():\n",
        "                    valid_indices = valid_masks.nonzero(as_tuple=True)[0]\n",
        "                    if len(valid_indices) > 0:\n",
        "                        seg_loss = focal_loss(outputs['segmentation'].squeeze(1)[valid_indices], seg_masks[valid_indices])\n",
        "\n",
        "                class_weight = 0.7 if valid_masks.any() else 1.0\n",
        "                seg_weight = 0.3 if valid_masks.any() else 0.0\n",
        "                loss = class_weight * class_loss + seg_weight * seg_loss\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "                train_class_loss += class_loss.item() if class_loss != 0 else 0\n",
        "                train_seg_loss += seg_loss.item() if seg_loss != 0 else 0\n",
        "                if valid_masks.any():\n",
        "                    valid_mask_batches += 1\n",
        "\n",
        "                train_bar.set_postfix({\n",
        "                    'Class Loss': f'{class_loss.item():.4f}' if class_loss != 0 else 'N/A',\n",
        "                    'Seg Loss': f'{seg_loss.item():.4f}' if seg_loss != 0 else '0.0',\n",
        "                    'Valid Masks': valid_mask_batches\n",
        "                })\n",
        "\n",
        "            avg_class_loss = train_class_loss / len(train_loader)\n",
        "            avg_seg_loss = train_seg_loss / valid_mask_batches if valid_mask_batches > 0 else 0.0\n",
        "            logging.info(f\"Epoch {epoch+1}/{epochs}, Class Loss: {avg_class_loss:.4f}, Seg Loss: {avg_seg_loss:.4f}, Valid Mask Batches: {valid_mask_batches}\")\n",
        "            print(f\"Epoch {epoch+1}/{epochs} - Class Loss: {avg_class_loss:.4f}, Seg Loss: {avg_seg_loss:.4f}, Valid Mask Batches: {valid_mask_batches}\")\n",
        "\n",
        "            # Evaluation\n",
        "            model.eval()\n",
        "            class_preds, class_true = [], []\n",
        "            seg_dice_scores = []\n",
        "            with torch.no_grad():\n",
        "                val_bar = tqdm(test_loader, desc=\"Validation\", leave=False)\n",
        "                for images, grading_labels, seg_masks, valid_masks, img_names in val_bar:\n",
        "                    images, grading_labels, seg_masks = images.to(device), grading_labels.to(device), seg_masks.to(device)\n",
        "                    valid_masks = valid_masks.to(device)\n",
        "                    outputs = model(images, task='both')\n",
        "\n",
        "                    if 'grading' in outputs:\n",
        "                        class_preds.extend(torch.argmax(outputs['grading'], dim=1).cpu().numpy())\n",
        "                        class_true.extend(grading_labels.cpu().numpy())\n",
        "                    if 'segmentation' in outputs and valid_masks.any():\n",
        "                        valid_indices = valid_masks.nonzero(as_tuple=True)[0]\n",
        "                        if len(valid_indices) > 0:\n",
        "                            seg_dice = dice_score(outputs['segmentation'].squeeze(1)[valid_indices], seg_masks[valid_indices])\n",
        "                            seg_dice_scores.append(seg_dice)\n",
        "\n",
        "            class_acc = accuracy_score([t for t in class_true if t != -1],\n",
        "                                      [p for t, p in zip(class_true, class_preds) if t != -1]) if class_true else 0\n",
        "            avg_dice = np.mean(seg_dice_scores) if seg_dice_scores else 0.0\n",
        "            logging.info(f\"Validation - Accuracy: {class_acc:.4f}, Dice: {avg_dice:.4f}\")\n",
        "            print(f\"Validation - Accuracy: {class_acc:.4f}, Dice: {avg_dice:.4f}\")\n",
        "\n",
        "            # Early stopping\n",
        "            if class_acc > best_acc:\n",
        "                best_acc = class_acc\n",
        "                torch.save(model.state_dict(), '/content/drive/MyDrive/IDRiD Dataset/best_model_2.pth')\n",
        "                logging.info(\"Saved best model based on classification accuracy\")\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    logging.info(f\"Early stopping triggered after {patience} epochs without improvement\")\n",
        "                    print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                    break\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        logging.warning(\"Training interrupted by user\")\n",
        "        print(\"Training interrupted. Saving current model state...\")\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/IDRiD Dataset/interrupted_model_2.pth')\n",
        "        logging.info(\"Saved interrupted model state to 'interrupted_model_2.pth'\")\n",
        "        return class_acc, avg_dice\n",
        "\n",
        "    return class_acc, avg_dice"
      ],
      "metadata": {
        "id": "fpZYv149dEUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization\n",
        "def visualize_results(model, test_loader, num_samples=5):\n",
        "    model.eval()\n",
        "    samples = []\n",
        "    try:\n",
        "        with torch.no_grad():\n",
        "            for images, _, seg_masks, valid_masks, img_names in test_loader:\n",
        "                images = images.to(device)\n",
        "                outputs = model(images, task='segmentation')\n",
        "                seg_preds = torch.sigmoid(outputs['segmentation'].squeeze(1)) > 0.1\n",
        "\n",
        "                for i in range(min(num_samples, images.size(0))):\n",
        "                    if not valid_masks[i]:\n",
        "                        continue\n",
        "                    img = images[i].cpu().permute(1, 2, 0).numpy()\n",
        "                    img = (img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])).clip(0, 1)\n",
        "                    pred_mask = seg_preds[i].cpu().numpy()\n",
        "                    true_mask = seg_masks[i].cpu().numpy()\n",
        "\n",
        "                    plt.figure(figsize=(15, 5))\n",
        "                    plt.subplot(1, 3, 1)\n",
        "                    plt.title(f\"Image: {img_names[i]}\")\n",
        "                    plt.imshow(img)\n",
        "                    plt.axis('off')\n",
        "                    plt.subplot(1, 3, 2)\n",
        "                    plt.title(\"Predicted Mask\")\n",
        "                    plt.imshow(pred_mask, cmap='gray')\n",
        "                    plt.axis('off')\n",
        "                    plt.subplot(1, 3, 3)\n",
        "                    plt.title(\"Ground Truth Mask\")\n",
        "                    plt.imshow(true_mask, cmap='gray')\n",
        "                    plt.axis('off')\n",
        "                    plt.savefig(f\"/content/drive/MyDrive/IDRiD Dataset/result_{img_names[i]}_2.png\")\n",
        "                    plt.close()\n",
        "                    samples.append(img_names[i])\n",
        "                    logging.info(f\"Generated visualization for {img_names[i]}\")\n",
        "                if len(samples) >= num_samples:\n",
        "                    break\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error during visualization: {str(e)}\")\n",
        "        print(f\"Error during visualization: {str(e)}\")"
      ],
      "metadata": {
        "id": "JoEXBKwRdAx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting training process...\")\n",
        "logging.info(\"Starting training process\")\n",
        "\n",
        "model = MultiTaskModel()\n",
        "# Unfreeze backbone for fine-tuning\n",
        "for param in model.backbone.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "print(\"Training MultiTaskModel...\")\n",
        "logging.info(\"Training MultiTaskModel\")\n",
        "class_acc, dice_score = train_model(model, train_loader, test_loader, epochs=50, patience=5)\n",
        "\n",
        "print(\"Generating visualizations...\")\n",
        "logging.info(\"Generating visualizations\")\n",
        "visualize_results(model, test_loader)\n",
        "\n",
        "logging.info(f\"Final MTL Results - Classification Accuracy: {class_acc:.4f}, Segmentation Dice: {dice_score:.4f}\")\n",
        "print(f\"Final MTL Results - Classification Accuracy: {class_acc:.4f}, Segmentation Dice: {dice_score:.4f}\")\n",
        "print(\"Training completed. Check 'training_2.log' for detailed logs and 'result_*_2.png' for visualizations.\")\n",
        "logging.info(\"Training completed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDc7xMMUcdY4",
        "outputId": "fcd1ac5d-ce56-4489-b078-da6278e09167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training process...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 181MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MultiTaskModel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50: 100%|██████████| 59/59 [01:35<00:00,  1.62s/it, Class Loss=0.8755, Seg Loss=0.1384, Valid Masks=37]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 - Class Loss: 1.7896, Seg Loss: 1.2798, Valid Mask Batches: 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.3010, Dice: 0.0829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50: 100%|██████████| 59/59 [01:42<00:00,  1.74s/it, Class Loss=2.0226, Seg Loss=0.0, Valid Masks=38]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/50 - Class Loss: 2.2298, Seg Loss: 0.0941, Valid Mask Batches: 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.1845, Dice: 0.0869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50: 100%|██████████| 59/59 [01:43<00:00,  1.75s/it, Class Loss=1.8490, Seg Loss=0.0, Valid Masks=38]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/50 - Class Loss: 1.7545, Seg Loss: 0.2253, Valid Mask Batches: 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.2233, Dice: 0.0820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50: 100%|██████████| 59/59 [01:43<00:00,  1.75s/it, Class Loss=1.6643, Seg Loss=0.0, Valid Masks=41]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/50 - Class Loss: 1.6411, Seg Loss: 0.1435, Valid Mask Batches: 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.3010, Dice: 0.1037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/50: 100%|██████████| 59/59 [01:40<00:00,  1.70s/it, Class Loss=1.3749, Seg Loss=0.0, Valid Masks=40]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/50 - Class Loss: 1.5993, Seg Loss: 0.1066, Valid Mask Batches: 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.3107, Dice: 0.1094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50: 100%|██████████| 59/59 [01:41<00:00,  1.72s/it, Class Loss=1.6561, Seg Loss=0.0690, Valid Masks=37]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/50 - Class Loss: 1.5521, Seg Loss: 0.0959, Valid Mask Batches: 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.3204, Dice: 0.0950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/50: 100%|██████████| 59/59 [01:41<00:00,  1.72s/it, Class Loss=1.5436, Seg Loss=0.0, Valid Masks=36]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/50 - Class Loss: 1.5245, Seg Loss: 0.0828, Valid Mask Batches: 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.2718, Dice: 0.1062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/50: 100%|██████████| 59/59 [01:41<00:00,  1.73s/it, Class Loss=1.3593, Seg Loss=0.0, Valid Masks=37]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/50 - Class Loss: 1.5331, Seg Loss: 0.0803, Valid Mask Batches: 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.3204, Dice: 0.1006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/50: 100%|██████████| 59/59 [01:41<00:00,  1.72s/it, Class Loss=1.5837, Seg Loss=0.0, Valid Masks=37]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/50 - Class Loss: 1.5266, Seg Loss: 0.0782, Valid Mask Batches: 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.2816, Dice: 0.1182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/50: 100%|██████████| 59/59 [01:39<00:00,  1.69s/it, Class Loss=1.3770, Seg Loss=0.0, Valid Masks=37]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/50 - Class Loss: 1.5891, Seg Loss: 0.0772, Valid Mask Batches: 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.2913, Dice: 0.1185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/50: 100%|██████████| 59/59 [01:39<00:00,  1.69s/it, Class Loss=1.9096, Seg Loss=0.0, Valid Masks=33]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/50 - Class Loss: 1.5134, Seg Loss: 0.0663, Valid Mask Batches: 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Accuracy: 0.2816, Dice: 0.1086\n",
            "Early stopping at epoch 11\n",
            "Generating visualizations...\n",
            "Final MTL Results - Classification Accuracy: 0.2816, Segmentation Dice: 0.1086\n",
            "Training completed. Check 'training_2.log' for detailed logs and 'result_*_2.png' for visualizations.\n"
          ]
        }
      ]
    }
  ]
}